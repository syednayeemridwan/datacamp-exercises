{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are they bots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: `@robot3!`, `@robot5&` and `@robot7#`\n",
    "\n",
    "To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the `.findall()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the re module\n",
    "# import re\n",
    "\n",
    "# # Write the regex\n",
    "# regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# # Find all matches of regex\n",
    "# print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You pull a list of metacharacters:`\\d` digit,`\\w` word character,`\\s` whitespace.\n",
    "\n",
    "Always indicate whitespace with metacharacters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex to obtain user mentions\n",
    "# print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))\n",
    "\n",
    "# # Write a regex to obtain number of likes\n",
    "# print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))\n",
    "\n",
    "# # Write a regex to obtain number of retweets\n",
    "# print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match and split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex to match pattern separating sentences\n",
    "# regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# # Replace the regex_sentence with a space\n",
    "# sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# # Write a regex to match pattern separating words\n",
    "# regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# # Replace the regex_words and print the result\n",
    "# sentiment_final = re.sub(regex_words, \" \", sentiment_sub)\n",
    "# print(sentiment_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import re module\n",
    "# import re\n",
    "\n",
    "# for tweet in sentiment_analysis:\n",
    "# \t# Write regex to match http links and print out result\n",
    "# \tprint(re.findall(r\"http\\w*\\W{3}\\w*\\W\\w*\\Wcom\", tweet))\n",
    "\n",
    "# \t# Write regex to match user mentions and print out result\n",
    "# \tprint(re.findall(r\"@\\w*\\d*\\w*\", tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some time ago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading a little bit more, you learn that dates are provided in different ways. You decide to extract the dates using .findall() so you can normalize them afterwards to make them all look the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complete the for loop with a regex to find dates\n",
    "# for date in sentiment_analysis:\n",
    "# \tprint(re.findall(r\"\\d{1,2}\\s\\w*\\s\\w*\", date))\n",
    " \n",
    "# # Complete the for loop with a regex to find dates\n",
    "# for date in sentiment_analysis:\n",
    "# \tprint(re.findall(r\"\\d{1,2}\\w{2}\\s\\w*\\s\\d{4}\", date))\n",
    " \n",
    "# # Complete the for loop with a regex to find dates\n",
    "# for date in sentiment_analysis:\n",
    "# \tprint(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex matching the hashtag pattern\n",
    "# regex = r\"#\\w+\"\n",
    "\n",
    "# # Replace the regex by an empty string\n",
    "# no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# # Get tokens by splitting text\n",
    "# print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are strings that refer to text file names.\n",
    "You also find a way to detect them:\n",
    "\n",
    "- They appear at the start of the string.\n",
    "- They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u).\n",
    "- They always finish with the txt ending.\n",
    "\n",
    "You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex to match text file name\n",
    "# regex = r\"^[aeiouAEIOU]{2,3}.+\\.txt\"\n",
    "\n",
    "# for text in sentiment_analysis:\n",
    "# \t# Find all matches of the regex\n",
    "# \tprint(re.findall(regex, text))\n",
    "# \t# Replace all matches with empty string\n",
    "# \tprint(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give me your email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.\n",
    "The company puts some rules in place to verify that the given email address is valid:\n",
    "\n",
    "- The first part can contain:\n",
    "- Upper A-Z or lowercase letters a-z\n",
    "- Numbers\n",
    "- Characters: !, #, %, &, *, $, .\n",
    "- Must have @\n",
    "- Domain:\n",
    "- Can contain any word characters\n",
    "- But only .com ending is allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex to match a valid email address\n",
    "# regex = r\"[a-zA-Z0-9!#%&*$\\.]+@\\w+\\.com\"\n",
    "\n",
    "# for example in emails:\n",
    "#   \t# Match the regex to the string\n",
    "#     if re.match(regex, example):\n",
    "#         # Complete the format method to print out the result\n",
    "#       \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "#     else:\n",
    "#       \tprint(\"The email {email_example} is invalid\".format(email_example=example))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invalid password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write a script that validates the password entered by the user. The company also puts some rules in order to verify valid passwords:\n",
    "\n",
    "- It can contain lowercase a-z and uppercase letters A-Z\n",
    "- It can contain numbers\n",
    "- It can contain the symbols: *, #, $, %, !, &, .\n",
    "- It must be at least 8 characters long but not more than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a regex to check if the password is valid\n",
    "# regex = r\"[a-zA-Z0-9\\*#\\$%!&\\.]{8,20}\"\n",
    "\n",
    "# for example in passwords:\n",
    "#   \t# Scan the strings to find a match\n",
    "#     if re.match(regex, example):\n",
    "#         # Complete the format method to print out the result\n",
    "#       \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "#     else:\n",
    "#       \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know that to get the HTML tag you need to match anything that sits inside angle brackets < >. But the biggest problem is that the closing tag has the same structure. If you match too much, you will end up removing key information. So you need to decide whether to use a greedy or a lazy quantifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import re\n",
    "# import re\n",
    "\n",
    "# # Write a regex to eliminate tags\n",
    "# string_notags = re.sub(r\"<.+?>\",\"\", string)\n",
    "\n",
    "# # Print out the result\n",
    "# print(string_notags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine that you want to extract the number contained in the sentence I was born on April 24th. A lazy quantifier will make the regex return 2 and 4, because they will match as few characters as needed. However, a greedy quantifier will return the entire 24 due to its need to match as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a lazy regex expression \n",
    "# numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
    "\n",
    "# # Print out the result\n",
    "# print(numbers_found_lazy)\n",
    "\n",
    "\n",
    "# # Write a greedy regex expression \n",
    "# numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# # Print out the result\n",
    "# print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract a word starting with a and ending with e in the string I like apple pie, you may think that applying the greedy regex a.+e will return apple. However, your match will be apple pie. A way to overcome this is to make it lazy by using ? which will return apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a greedy regex expression to match \n",
    "# sentences_found_greedy = re.findall(r\"\\(.*a.*e\\)\", sentiment_analysis)\n",
    "\n",
    "# # Print out the result\n",
    "# print(sentences_found_greedy)\n",
    "\n",
    "# # Write a lazy regex expression\n",
    "# sentences_found_lazy = re.findall(r\"\\(.*?a.*?e\\)\", sentiment_analysis)\n",
    "\n",
    "# # Print out the results\n",
    "# print(sentences_found_lazy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc575bfddb5c8ca4bb6a4f4dcdd32abc104b5fa4177361381c432fff36ce3e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
