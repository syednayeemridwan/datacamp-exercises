{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxing Exercise: Compute the ACF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last chapter, you computed autocorrelations with one lag. Often we are interested in seeing the autocorrelation over many lags. The quarterly earnings for H&R Block (ticker symbol HRB) is plotted on the right, and you can see the extreme cyclicality of its earnings. A vast majority of its earnings occurs in the quarter that taxes are due.\n",
    "\n",
    "You will compute the array of autocorrelations for the H&R Block quarterly earnings that is pre-loaded in the DataFrame HRB. Then, plot the autocorrelation function using the `plot_acf` module. This plot shows what the autocorrelation function looks like for cyclical earnings data. The ACF at `lag=0` is always one, of course. In the next exercise, you will learn about the confidence interval for the ACF, but for now, suppress the confidence interval by setting `alpha=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the acf module and the plot_acf module from statsmodels\n",
    "# from statsmodels.tsa.stattools import acf\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# # Compute the acf array of HRB\n",
    "# acf_array = acf(HRB)\n",
    "# print(acf_array)\n",
    "\n",
    "# # Plot the acf function\n",
    "# plot_acf(HRB,alpha=1)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are We Confident This Stock is Mean Reverting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last chapter, you saw that the autocorrelation of MSFT's weekly stock returns was -0.16. That autocorrelation seems large, but is it statistically significant? In other words, can you say that there is less than a 5% chance that we would observe such a large negative autocorrelation if the true autocorrelation were really zero? And are there any autocorrelations at other lags that are significantly different from zero?\n",
    "\n",
    "Even if the true autocorrelations were zero at all lags, in a finite sample of returns you won't see the estimate of the autocorrelations exactly zero. In fact, the standard deviation of the sample autocorrelation is 1/sqrt(N)  where N is the number of observations, so if N = 100\n",
    ", for example, the standard deviation of the ACF is 0.1, and since 95% of a normal curve is between +1.96 and -1.96 standard deviations from the mean, the 95% confidence interval is 1.96/sqrt(N). This approximation only holds when the true autocorrelations are all zero.\n",
    "\n",
    "You will compute the actual and approximate confidence interval for the ACF, and compare it to the lag-one autocorrelation of -0.16 from the last chapter. The weekly returns of Microsoft is pre-loaded in a DataFrame called returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the plot_acf module from statsmodels and sqrt from math\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "# from math import sqrt\n",
    "\n",
    "# # Compute and print the autocorrelation of MSFT weekly returns\n",
    "# autocorrelation = returns['Adj Close'].autocorr()\n",
    "# print(\"The autocorrelation of weekly MSFT returns is %4.2f\" %(autocorrelation))\n",
    "\n",
    "# # Find the number of observations by taking the length of the returns DataFrame\n",
    "# nobs = len(returns['Adj Close'])\n",
    "\n",
    "# # Compute the approximate confidence interval\n",
    "# conf = 1.96/sqrt(nobs)\n",
    "# print(\"The approximate confidence interval is +/- %4.2f\" %(conf))\n",
    "\n",
    "# # Plot the autocorrelation function with 95% confidence intervals and 20 lags using plot_acf\n",
    "# plot_acf(returns, alpha=0.05, lags=20)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can't Forecast White Noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A white noise time series is simply a sequence of uncorrelated random variables that are identically distributed. Stock returns are often modeled as white noise. Unfortunately, for white noise, we cannot forecast future observations based on the past - autocorrelations at all lags are zero.\n",
    "\n",
    "You will generate a white noise series and plot the autocorrelation function to show that it is zero for all lags. You can use `np.random.normal()` to generate random returns. For a Gaussian white noise process, the mean and standard deviation describe the entire process.\n",
    "\n",
    "Plot this white noise series to see what it looks like, and then plot the autocorrelation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the plot_acf module from statsmodels\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# # Simulate white noise returns\n",
    "# returns = np.random.normal(loc=0.02, scale=0.05, size=1000)\n",
    "\n",
    "# # Print out the mean and standard deviation of returns\n",
    "# mean = np.mean(returns)\n",
    "# std = np.std(returns)\n",
    "# print(\"The mean is %5.3f and the standard deviation is %5.3f\" %(mean,std))\n",
    "\n",
    "# # Plot returns series\n",
    "# plt.plot(returns)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot autocorrelation function of white noise returns\n",
    "# plot_acf(returns, lags=20)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Random Walk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas stock returns are often modeled as white noise, stock prices closely follow a random walk. In other words, today's price is yesterday's price plus some random noise.\n",
    "\n",
    "You will simulate the price of a stock over time that has a starting price of 100 and every day goes up or down by a random amount. Then, plot the simulated stock price. If you hit the \"Run Code\" code button multiple times, you'll see several realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate 500 random steps with mean=0 and standard deviation=1\n",
    "# steps = np.random.normal(loc=0, scale=1, size=500)\n",
    "\n",
    "# # Set first element to 0 so that the first price will be the starting stock price\n",
    "# steps[0]=0\n",
    "\n",
    "# # Simulate stock prices, P with a starting price of 100\n",
    "# P = 100 + np.cumsum(steps)\n",
    "\n",
    "# # Plot the simulated stock prices\n",
    "# plt.plot(P)\n",
    "# plt.title(\"Simulated Random Walk\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Drift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, you simulated stock prices that follow a random walk. You will extend this in two ways in this exercise.\n",
    "\n",
    "You will look at a random walk with a drift. Many time series, like stock prices, are random walks but tend to drift up over time.\n",
    "In the last exercise, the noise in the random walk was additive: random, normal changes in price were added to the last price. However, when adding noise, you could theoretically get negative prices. Now you will make the noise multiplicative: you will add one to the random, normal changes to get a total return, and multiply that by the last price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate 500 random steps\n",
    "# steps = np.random.normal(loc=0.001, scale=0.01, size=500) + 1\n",
    "\n",
    "# # Set first element to 1\n",
    "# steps[0]=1\n",
    "\n",
    "# # Simulate the stock price, P, by taking the cumulative product\n",
    "# P = 100 * np.cumprod(steps)\n",
    "\n",
    "# # Plot the simulated stock prices\n",
    "# plt.plot(P)\n",
    "# plt.title(\"Simulated Random Walk with Drift\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are Stock Prices a Random Walk?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most stock prices follow a random walk (perhaps with a drift). You will look at a time series of Amazon stock prices, pre-loaded in the DataFrame AMZN, and run the 'Augmented Dickey-Fuller Test' from the statsmodels library to show that it does indeed follow a random walk.\n",
    "\n",
    "With the ADF test, the \"null hypothesis\" (the hypothesis that we either reject or fail to reject) is that the series follows a random walk. Therefore, a low p-value (say less than 5%) means we can reject the null hypothesis that the series is a random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the adfuller module from statsmodels\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# # Run the ADF test on the price series and print out the results\n",
    "# results = adfuller(AMZN['Adj Close'])\n",
    "# print(results)\n",
    "\n",
    "# # Just print out the p-value\n",
    "# print('The p-value of the test on prices is: ' + str(results[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How About Stock Returns?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, you showed that Amazon stock prices, contained in the DataFrame AMZN follow a random walk. In this exercise. you will do the same thing for Amazon returns (percent change in prices) and show that the returns do not follow a random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the adfuller module from statsmodels\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# # Create a DataFrame of AMZN returns\n",
    "# AMZN_ret = AMZN.pct_change()\n",
    "\n",
    "# # Eliminate the NaN in the first row of returns\n",
    "# AMZN_ret = AMZN_ret.dropna()\n",
    "\n",
    "# # Run the ADF test on the return series and print out the p-value\n",
    "# results = adfuller(AMZN_ret['Adj Close'])\n",
    "# print('The p-value of the test on returns is: ' + str(results[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is it Stationary?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are four time series plots:\n",
    "<center><img src=\"images/02.12.png\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "\n",
    "Which one is stationary?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Adjustment During Tax Season"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many time series exhibit strong seasonal behavior. The procedure for removing the seasonal component of a time series is called seasonal adjustment. For example, most economic data published by the government is seasonally adjusted.\n",
    "\n",
    "You saw earlier that by taking first differences of a random walk, you get a stationary white noise process. For seasonal adjustments, instead of taking first differences, you will take differences with a lag corresponding to the periodicity.\n",
    "\n",
    "Look again at the ACF of H&R Block's quarterly earnings, pre-loaded in the DataFrame `HRB`, and there is a clear seasonal component. The autocorrelation is high for lags 4,8,12,16,â€¦ because of the spike in earnings every four quarters during tax season. Apply a seasonal adjustment by taking the fourth difference (four represents the periodicity of the series). Then compute the autocorrelation of the transformed series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the plot_acf module from statsmodels\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# # Seasonally adjust quarterly earnings\n",
    "# HRBsa = HRB.diff(4)\n",
    "\n",
    "# # Print the first 10 rows of the seasonally adjusted series\n",
    "# print(HRBsa.head(10))\n",
    "\n",
    "# # Drop the NaN data in the first four rows\n",
    "# HRBsa = HRBsa.dropna()\n",
    "\n",
    "# # Plot the autocorrelation function of the seasonally adjusted series\n",
    "# plot_acf(HRBsa)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc575bfddb5c8ca4bb6a4f4dcdd32abc104b5fa4177361381c432fff36ce3e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
