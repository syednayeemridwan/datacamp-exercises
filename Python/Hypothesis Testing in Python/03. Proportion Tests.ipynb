{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t for proportions?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the hypothesis tests in this course have used a t test statistic and some have used a \n",
    "z test statistic. To get the correct p-value, you need to use the right type of test statistic.\n",
    "\n",
    "Do tests of proportion(s) use a z or a t test statistic and why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z: The test statistic for proportion(s) has only one estimate of a parameter instead of two."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for single proportions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 1, you calculated a p-value for a test hypothesizing that the proportion of late shipments was greater than 6%. In that chapter, you used a bootstrap distribution to estimate the standard error of the statistic. An alternative is to use an equation for the standard error based on the sample proportion, hypothesized proportion, and sample size.\n",
    " \n",
    "<center><img src=\"images/03.01.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "\n",
    "You'll revisit the p-value using this simpler calculation.\n",
    "\n",
    "`late_shipments` is available. pandas and numpy are available under their usual aliases, and norm is loaded from scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hypothesize that the proportion of late shipments is 6%\n",
    "# p_0 = 0.06\n",
    "\n",
    "# # Calculate the sample proportion of late shipments\n",
    "# p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# # Calculate the sample size\n",
    "# n = len(late_shipments)\n",
    "\n",
    "# # Calculate the numerator and denominator of the test statistic\n",
    "# numerator = p_hat - p_0\n",
    "# denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# # Calculate the test statistic\n",
    "# z_score = numerator / denominator\n",
    "\n",
    "# # Calculate the p-value from the z-score\n",
    "# p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# # Print the p-value\n",
    "# print(p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of two proportions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder if the amount paid for freight affects whether or not the shipment was late. Recall that in the `late_shipments` dataset, whether or not the shipment was late is stored in the `late` column. Freight costs are stored in the `freight_cost_group` column, and the categories are `\"expensive\"` and `\"reasonable\"`.\n",
    "\n",
    "The hypotheses to test, with \"late\" corresponding to the proportion of late shipments for that group, are\n",
    "\n",
    "H0: late_expensive - late_reasonable = 0\n",
    "\n",
    "HA: late_expensive - late_reasonable > 0\n",
    "\n",
    "`p_hats` contains the estimates of population proportions (sample proportions) for each `freight_cost_group`:\n",
    "```\n",
    "freight_cost_group  late\n",
    "expensive           Yes     0.082569\n",
    "reasonable          Yes     0.035165\n",
    "Name: late, dtype: float64\n",
    "```\n",
    "`ns` contains the sample sizes for these groups:\n",
    "```\n",
    "freight_cost_group\n",
    "expensive     545\n",
    "reasonable    455\n",
    "Name: late, dtype: int64\n",
    "```\n",
    "pandas and numpy have been imported under their usual aliases, and norm is available from scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the pooled estimate of the population proportion\n",
    "# p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# # Calculate p_hat one minus p_hat\n",
    "# p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# # Divide this by each of the sample sizes and then sum\n",
    "# p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# # Calculate the standard error\n",
    "# std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# # Calculate the z-score\n",
    "# z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# # Calculate the p-value from the z-score\n",
    "# p_value = 1-norm.cdf(z_score)\n",
    "\n",
    "# # Print p_value\n",
    "# print(p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proportions_ztest() for two samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a lot of effort to calculate the p-value, so while it is useful to see how the calculations work, it isn't practical to do in real-world analyses. For daily usage, it's better to use the statsmodels package.\n",
    "\n",
    "Recall the hypotheses.\n",
    "\n",
    "`late_shipments` is available, containing the freight_cost_group column. numpy and pandas have been loaded under their standard aliases, and proportions_ztest has been loaded from statsmodels.stats.proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the late column values for each freight_cost_group\n",
    "# late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# # Create an array of the \"Yes\" counts for each freight_cost_group\n",
    "# success_counts = np.array([45, 16])\n",
    "\n",
    "# # Create an array of the total number of rows in each freight_cost_group\n",
    "# n = np.array([500+45, 439+16])\n",
    "\n",
    "# # Run a z-test on the two proportions\n",
    "# stat, p_value = proportions_ztest(count=success_counts, \n",
    "#                                      nobs=n,\n",
    "#                                      alternative=\"larger\")\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# print(stat, p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The chi-square distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-square hypothesis tests rely on the chi-square distribution. Like the t-distribution, it has degrees of freedom and non-centrality parameters.\n",
    "\n",
    "The plots show the PDF and CDF for a chi-square distribution (solid black line), and for comparison show a normal distribution with the same mean and variance (gray dotted line).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/03.081.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/03.082.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/03.083.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n",
    "<center><img src=\"images/03.084.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which statement about the chi-square distribution is true?\n",
    "- As you increase the degrees of freedom or the non-centrality, the chi-square distribution PDF and CDF curves get closer to those of a normal distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many tails for chi-square tests?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `pingouin.ttest()` and `statsmodels.stats.proportion.proportions_ztest()`, `pingouin.chi2_independence()` does not have an alternative argument to specify which tails are considered by the alternative hypothesis.\n",
    "\n",
    "Which tail is almost always considered in chi-square tests?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right-tailed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a chi-square test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-square independence test compares proportions of successes of one categorical variable across the categories of another categorical variable.\n",
    "\n",
    "Trade deals often use a form of business shorthand in order to specify the exact details of their contract. These are International Chamber of Commerce (ICC) international commercial terms, or incoterms for short.\n",
    "\n",
    "The `late_shipments` dataset includes a `vendor_inco_term` that describes the incoterms that applied to a given shipment. The choices are:\n",
    "\n",
    "- EXW: \"Ex works\". The buyer pays for transportation of the goods.\n",
    "- CIP: \"Carriage and insurance paid to\". The seller pays for freight and insurance until the goods board a ship.\n",
    "- DDP: \"Delivered duty paid\". The seller pays for transportation of the goods until they reach a destination port.\n",
    "- FCA: \"Free carrier\". The seller pays for transportation of the goods.\n",
    "Perhaps the incoterms affect whether or not the freight costs are expensive. Test these hypotheses with a significance level of 0.01.\n",
    "\n",
    "H0 : vendor_inco_term and freight_cost_group are independent.\n",
    "\n",
    "HA : vendor_inco_term and freight_cost_group are associated.\n",
    "\n",
    "`late_shipments` is available, and the following have been loaded: `matplotlib.pyplot as plt`, `pandas as pd`, and `pingouin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "# props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# # Convert props to wide format\n",
    "# wide_props = props.unstack()\n",
    "\n",
    "# # Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "# wide_props.plot(kind=\"bar\", stacked=True)\n",
    "# plt.show()\n",
    "\n",
    "# # Determine if freight_cost_group and vendor_inco_term are independent\n",
    "# expected, observed, stats = pingouin.chi2_independence(data=late_shipments, \n",
    "# x='vendor_inco_term',y='freight_cost_group', correction=False)\n",
    "\n",
    "# # Print results\n",
    "# print(stats[stats['test'] == 'pearson']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should you conclude from the hypothesis test?\n",
    "- Reject the null hypothesis and conclude that `vendor_inco_term` and `freight_cost_group` are associated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing goodness of fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-square goodness of fit test compares proportions of each level of a categorical variable to hypothesized values. Before running such a test, it can be helpful to visually compare the distribution in the sample to the hypothesized distribution.\n",
    "\n",
    "Recall the vendor incoterms in the `late_shipments` dataset. You hypothesize that the four values occur with these frequencies in the population of shipments.\n",
    "\n",
    "- CIP: 0.05\n",
    "- DDP: 0.1\n",
    "- EXW: 0.75\n",
    "- FCA: 0.1\n",
    "These frequencies are stored in the `hypothesized` DataFrame.\n",
    "\n",
    "The `incoterm_counts` DataFrame stores the `.value_counts()` of the `vendor_inco_term` column.\n",
    "\n",
    "`late_shipments` is available; `pandas` and `matplotlib.pyplot` are loaded with their standard aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the number of rows in late_shipments\n",
    "# n_total = len(late_shipments)\n",
    "\n",
    "# # Create n column that is prop column * n_total\n",
    "# hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# # Plot a red bar graph of n vs. vendor_inco_term for incoterm_counts\n",
    "# plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"red\", label=\"Observed\")\n",
    "\n",
    "# # Add a blue bar plot for the hypothesized counts\n",
    "# plt.bar(hypothesized['vendor_inco_term'], hypothesized['n'], color=\"blue\",alpha=0.5,label=\"Hypothesized\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a goodness of fit test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot of `vendor_inco_term` suggests that the distribution across the four categories was quite close to the hypothesized distribution. You'll need to perform a chi-square goodness of fit test to see whether the differences are statistically significant.\n",
    "\n",
    "Recall the hypotheses for this type of test:\n",
    "\n",
    "H0: The sample matches with the hypothesized distribution.\n",
    "\n",
    "HA: The sample does not match with the hypothesized distribution.\n",
    "\n",
    "To decide which hypothesis to choose, we'll set a significance level of 0.1.\n",
    "\n",
    "`late_shipments`, `incoterm_counts`, and `hypothesized` from the last exercise are available. chisquare from `scipy.stats` has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform a goodness of fit test on the incoterm counts n\n",
    "# gof_test = chisquare(f_obs=incoterm_counts['n'], f_exp=hypothesized['n'])\n",
    "\n",
    "\n",
    "# # Print gof_test results\n",
    "# print(gof_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should you conclude from the hypothesis test?\n",
    "- Fail to reject the null hypothesis and conclude that n follows the distribution specified by hypothesized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
