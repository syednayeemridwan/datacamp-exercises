{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a parallel slopes linear regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, using only one explanatory variable limits the accuracy of predictions. To truly master linear regression, you need to be able to fit regression models with multiple explanatory variables.\n",
    "\n",
    "The case when there is one numeric explanatory variable and one categorical explanatory variable is sometimes called a \"parallel slopes\" linear regression due to the shape of the predictions — more on that in the next exercise.\n",
    "\n",
    "Here, you'll revisit the Taiwan real estate dataset. Recall the meaning of each variable.\n",
    "\n",
    "- `dist_to_mrt_station_m` = Distance to nearest MRT metro station, in meters.\n",
    "- `n_convenience` = No. of convenience stores in walking distance.\n",
    "- `house_age_years` = The age of the house, in years, in 3 groups.\n",
    "- `price_twd_msq` = House price per unit area, in New Taiwan dollars per meter squared.\n",
    "\n",
    "`taiwan_real_estate` is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import ols from statsmodels.formula.api\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "# # Fit a linear regression of price_twd_msq vs. n_convenience\n",
    "# mdl_price_vs_conv = ols(\"price_twd_msq ~ n_convenience\",\n",
    "#                         data=taiwan_real_estate).fit()\n",
    "\n",
    "# # Fit a linear regression of price_twd_msq vs. house_age_years, no intercept\n",
    "# mdl_price_vs_age = ols(\"price_twd_msq ~ house_age_years + 0\", data=taiwan_real_estate).fit()\n",
    "\n",
    "# # Fit a linear regression of price_twd_msq vs. n_convenience plus house_age_years, no intercept\n",
    "# mdl_price_vs_both = ols(\"price_twd_msq ~ n_convenience + house_age_years + 0\", data=taiwan_real_estate).fit()\n",
    "\n",
    "# # Print the coefficients\n",
    "# print(mdl_price_vs_both.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting parallel slopes coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression with a single numeric explanatory variable, there is an intercept coefficient and a slope coefficient. For linear regression with a single categorical explanatory variable, there is an intercept coefficient for each category.\n",
    "\n",
    "In the \"parallel slopes\" case, where you have a numeric and a categorical explanatory variable, what do the coefficients mean?\n",
    "\n",
    "`taiwan_real_estate` and `mdl_price_vs_both` are available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the coefficients of `mdl_price_vs_both`. What is the meaning of the `n_convenience` coefficient?\n",
    "- For each additional nearby convenience store, the expected house price, in TWD per square meter, increases by 0.79."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the meaning of the \"0 to 15 years\" coefficient?\n",
    "- For a house aged 0 to 15 years with zero nearby convenience stores, the expected house price is 9.41 TWD per square meter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing each explanatory variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to see the predictions made by a model makes it easier to understand. In the case where there is only one explanatory variable, `seaborn` lets you do this without any manual calculation.\n",
    "\n",
    "To visualize the relationship between a numeric explanatory variable and the numeric response, you can draw a scatter plot with a linear trend line.\n",
    "\n",
    "To visualize the relationship between a categorical explanatory variable and the numeric response, you can draw a box plot.\n",
    "\n",
    "`taiwan_real_estate` is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import matplotlib.pyplot and seaborn\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a scatter plot with linear trend line of price_twd_msq vs. n_convenience\n",
    "# sns.regplot(x = \"n_convenience\", y = \"price_twd_msq\", data = taiwan_real_estate)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import matplotlib.pyplot and seaborn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Create a boxplot of price_twd_msq vs. house_age_years\n",
    "# sns.boxplot(x = \"house_age_years\", y = \"price_twd_msq\", data = taiwan_real_estate)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing parallel slopes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two plots in the previous exercise gave very different predictions: one gave a predicted response that increased linearly with a numeric variable; the other gave a fixed response for each category. The only sensible way to reconcile these two conflicting predictions is to incorporate both explanatory variables in the model at once.\n",
    "\n",
    "When it comes to a linear regression model with a numeric and a categorical explanatory variable, `seaborn` doesn't have an easy, \"out of the box\" way to show the predictions.\n",
    "\n",
    "`taiwan_real_estate` is available and `mdl_price_vs_both` is available as a fitted model. `seaborn` is imported as `sns` and `matplotlib.pyplot` is imported as `plt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the model coefficients, coeffs\n",
    "# coeffs = mdl_price_vs_both.params\n",
    "\n",
    "# # Assign each of the coeffs\n",
    "# ic_0_15, ic_15_30, ic_30_45, slope = coeffs\n",
    "\n",
    "# # Draw a scatter plot of price_twd_msq vs. n_convenience, colored by house_age_years\n",
    "# sns.scatterplot(x=\"n_convenience\",\n",
    "#                 y=\"price_twd_msq\",\n",
    "#                 hue=\"house_age_years\",\n",
    "#                 data=taiwan_real_estate)\n",
    "\n",
    "# # Add three parallel lines for each category of house_age_years\n",
    "# # Color the line for ic_0_15 blue\n",
    "# plt.axline(xy1=(0, ic_0_15), slope=slope, color=\"blue\")\n",
    "# # Color the line for ic_15_30 orange\n",
    "# plt.axline(xy1=(0, ic_15_30), slope=slope, color=\"orange\")\n",
    "# # Color the line for ic_30_45 green\n",
    "# plt.axline(xy1=(0, ic_30_45), slope=slope, color=\"green\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with a parallel slopes model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `seaborn` can automatically show you model predictions using `sns.regplot()`, in order to get those values to program with, you'll need to do the calculations yourself.\n",
    "\n",
    "Just as with the case of a single explanatory variable, the workflow has two steps: create a DataFrame of explanatory variables, then add a column of predictions.\n",
    "\n",
    "`taiwan_real_estate` is available and `mdl_price_vs_both` is available as a fitted model. `seaborn`, `ols()`, `matplotlib.pyplot`, `pandas`, and `numpy` are loaded as their default aliases. This will also be the case for the remainder of the course. In addition, `ìtertools`.product is available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create n_convenience as a range of numbers from 0 to 10\n",
    "# n_convenience = np.arange(0, 11)\n",
    "\n",
    "# # Extract the unique values of house_age_years\n",
    "# house_age_years = taiwan_real_estate[\"house_age_years\"].unique()\n",
    "\n",
    "# # Create p as all combinations of values of n_convenience and house_age_years\n",
    "# p = product(n_convenience, house_age_years)\n",
    "\n",
    "# # Transform p to a DataFrame and name the columns\n",
    "# explanatory_data = pd.DataFrame(p, columns=['n_convenience', 'house_age_years'])\n",
    "\n",
    "# # Add predictions to the DataFrame\n",
    "# prediction_data = explanatory_data.assign(\n",
    "#     price_twd_msq = mdl_price_vs_both.predict(explanatory_data)\n",
    "# )\n",
    "\n",
    "# print(prediction_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing parallel slopes model predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you've got the right predictions from the previous exercise, you can add them to a `seaborn` plot. To visualize multiple regression predictions, you use the same procedure as with linear regression: draw a scatter plot with a trend line and add a second layer of prediction points on the same plot. As you've seen in a previous exercise, `seaborn` can't plot the parallel slopes model directly. Therefore, you'll first re-extract the model coefficients before you plot the prediction points.\n",
    "\n",
    "`taiwan_real_estate` and `prediction_data` are available, and `mdl_price_vs_both` is available as a fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the model coefficients, coeffs\n",
    "# coeffs = mdl_price_vs_both.params\n",
    "\n",
    "# # Assign each of the coeffs\n",
    "# ic_0_15, ic_15_30, ic_30_45, slope = coeffs\n",
    "\n",
    "# # Create the parallel slopes plot\n",
    "# plt.axline(xy1=(0, ic_0_15), slope=slope, color=\"green\")\n",
    "# plt.axline(xy1=(0, ic_15_30), slope=slope, color=\"orange\")\n",
    "# plt.axline(xy1=(0, ic_30_45), slope=slope, color=\"blue\")\n",
    "# sns.scatterplot(x=\"n_convenience\",\n",
    "#                 y=\"price_twd_msq\",\n",
    "#                 hue=\"house_age_years\",\n",
    "#                 data=taiwan_real_estate)\n",
    "\n",
    "# # Add the predictions in black\n",
    "# sns.scatterplot(x=\"n_convenience\",\n",
    "#                 y=\"price_twd_msq\",\n",
    "#                 color=\"black\",\n",
    "#                 data=prediction_data)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually calculating predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with simple linear regression, you can also manually calculate the predictions from the model coefficients. The only change for the parallel slopes case is that the intercept is different for each category of the categorical explanatory variable. That means you need to consider the case when each category occurs separately.\n",
    "\n",
    "`taiwan_real_estate`, `mdl_price_vs_both`, and `explanatory_data` are available; `ic_0_15`, `ic_15_30`, `ic_30_45`, and `slope` from the previous exercise are also loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define conditions\n",
    "# conditions = [explanatory_data[\"house_age_years\"]==\"0 to 15\",\n",
    "# \texplanatory_data[\"house_age_years\"]==\"15 to 30\",\n",
    "# \texplanatory_data[\"house_age_years\"]==\"30 to 45\"]\n",
    "\n",
    "# # Define choices\n",
    "# choices = [ic_0_15,ic_15_30,ic_30_45]\n",
    "\n",
    "# # Create array of intercepts for each house_age_year category\n",
    "# intercept = np.select(conditions, choices)\n",
    "\n",
    "# # Create prediction_data with columns intercept and price_twd_msq\n",
    "# prediction_data = explanatory_data.assign(\n",
    "# \t\t\t      intercept = np.select(conditions, choices),\n",
    "#   \t\t\t      price_twd_msq = intercept + slope * explanatory_data[\"n_convenience\"])\n",
    "\n",
    "# print(prediction_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing coefficients of determination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the coefficient of determination is a measure of how well the linear regression line fits the observed values. An important motivation for including several explanatory variables in a linear regression is that you can improve the fit compared to considering only a single explanatory variable.\n",
    "\n",
    "Here you'll compare the coefficient of determination for the three Taiwan house price models, to see which gives the best result.\n",
    "\n",
    "`mdl_price_vs_conv`, `mdl_price_vs_age`, and `mdl_price_vs_both` are available as fitted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the coeffs of determination for mdl_price_vs_conv\n",
    "# print(\"rsquared_conv: \", mdl_price_vs_conv.rsquared)\n",
    "# print(\"rsquared_adj_conv: \", mdl_price_vs_conv.rsquared_adj)\n",
    "\n",
    "# # Print the coeffs of determination for mdl_price_vs_age\n",
    "# print(\"rsquared_age: \", mdl_price_vs_age.rsquared)\n",
    "# print(\"rsquared_adj_age: \", mdl_price_vs_age.rsquared_adj)\n",
    "\n",
    "# # Print the coeffs of determination for mdl_price_vs_both\n",
    "# print(\"rsquared_both: \", mdl_price_vs_both.rsquared)\n",
    "# print(\"rsquared_adj_both: \", mdl_price_vs_both.rsquared_adj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model does the adjusted coefficient of determination suggest gives a better fit?\n",
    "- `mdl_price_vs_both`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing residual standard error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other common metric for assessing model fit is the residual standard error (RSE), which measures the typical size of the residuals.\n",
    "\n",
    "RSE can't directly be retrieved using `statsmodels`, but you can retrieve the mean squared error (MSE) using the `.mse_resid` attribute. By taking the square root of the MSE, you can get the RSE.\n",
    "\n",
    "In the last exercise, you saw how including both explanatory variables into the model increased the coefficient of determination. How do you think using both explanatory variables will change the RSE?\n",
    "\n",
    "`mdl_price_vs_conv`, `mdl_price_vs_age`, and `mdl_price_vs_both` are available as fitted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the RSE for mdl_price_vs_conv\n",
    "# print(\"rse_conv: \", np.sqrt(mdl_price_vs_conv.mse_resid))\n",
    "\n",
    "# # Print the RSE for mdl_price_vs_age\n",
    "# print(\"rse_age: \", np.sqrt(mdl_price_vs_age.mse_resid))\n",
    "\n",
    "# # Print RSE for mdl_price_vs_both\n",
    "# print(\"rse_both: \", np.sqrt(mdl_price_vs_both.mse_resid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model does the RSE suggest gives more accurate predictions?\n",
    "- `mdl_price_vs_both`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
