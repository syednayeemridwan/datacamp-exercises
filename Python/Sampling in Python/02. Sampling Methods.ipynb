{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple random sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method of sampling a population is the one you've seen already. It is known as simple random sampling (sometimes abbreviated to \"SRS\"), and involves picking rows at random, one at a time, where each row has the same chance of being picked as any other.\n",
    "\n",
    "In this chapter, you'll apply sampling methods to a synthetic (fictional) employee attrition dataset from IBM, where \"attrition\" in this context means leaving the company.\n",
    "\n",
    "`attrition_pop` is available; `pandas` as `pd` is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample 70 rows using simple random sampling and set the seed\n",
    "# attrition_samp = attrition_pop.sample(n=70, random_state = 18900217)\n",
    "\n",
    "# # Print the sample\n",
    "# print(attrition_samp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sampling method that avoids randomness is called systematic sampling. Here, you pick rows from the population at regular intervals.\n",
    "\n",
    "For example, if the population dataset had one thousand rows, and you wanted a sample size of five, you could pick rows 0, 200, 400, 600, and 800.\n",
    "\n",
    "`attrition_pop` is available; `pandas` has been pre-loaded as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the sample size to 70\n",
    "# sample_size = 70\n",
    "\n",
    "# # Calculate the population size from attrition_pop\n",
    "# pop_size = len(attrition_pop)\n",
    "\n",
    "# # Calculate the interval\n",
    "# interval = pop_size // sample_size\n",
    "\n",
    "# # Systematically sample 70 rows\n",
    "# attrition_sys_samp = attrition_pop[::interval]\n",
    "\n",
    "# # Print the sample\n",
    "# print(attrition_sys_samp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is systematic sampling OK?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systematic sampling has a problem: if the data has been sorted, or there is some sort of pattern or meaning behind the row order, then the resulting sample may not be representative of the whole population. The problem can be solved by shuffling the rows, but then systematic sampling is equivalent to simple random sampling.\n",
    "\n",
    "Here you'll look at how to determine whether or not there is a problem.\n",
    "\n",
    "`attrition_pop` is available; `pandas` is loaded as `pd`, and `matplotlib.pyplot` as `plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add an index column to attrition_pop\n",
    "# attrition_pop_id = attrition_pop.reset_index()\n",
    "\n",
    "# # Plot YearsAtCompany vs. index for attrition_pop_id\n",
    "# attrition_pop_id.plot(x = \"index\", y = \"YearsAtCompany\", kind = \"scatter\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the rows of attrition_pop\n",
    "# attrition_shuffled = attrition_pop.sample(frac=1)\n",
    "\n",
    "# # Reset the row indexes and create an index column\n",
    "# attrition_shuffled = attrition_shuffled.reset_index(drop = True).reset_index()\n",
    "\n",
    "# # Plot YearsAtCompany vs. index for attrition_shuffled\n",
    "# attrition_shuffled.plot(x = \"index\", y = \"YearsAtCompany\", kind = \"scatter\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does a systematic sample always produce a sample similar to a simple random sample?\n",
    "- No. This is not true if the data is sorted in some way."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which sampling method?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned about several sampling methods, including simple random sampling and stratified sampling. It's important to know when to use each of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/02.06.jpg\"  style=\"width: 400px, height: 300px;\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportional stratified sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in subgroups within the population, then you may need to carefully control the counts of each subgroup within the population. Proportional stratified sampling results in subgroup sizes within the sample that are representative of the subgroup sizes within the population. It is equivalent to performing a simple random sample on each subgroup.\n",
    "\n",
    "`attrition_pop` is available; `pandas` is loaded with its usual alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Proportion of employees by Education level\n",
    "# education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)\n",
    "\n",
    "# # Print education_counts_pop\n",
    "# print(education_counts_pop)\n",
    "\n",
    "# # Proportional stratified sampling for 40% of each Education group\n",
    "# attrition_strat = attrition_pop.groupby('Education')\\\n",
    "# \t.sample(frac=0.4, random_state=2022)\n",
    "\n",
    "# # Calculate the Education level proportions from attrition_strat\n",
    "# education_counts_strat = attrition_strat['Education'].value_counts(normalize=True)\n",
    "\n",
    "# # Print education_counts_strat\n",
    "# print(education_counts_strat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equal counts stratified sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one subgroup is larger than another subgroup in the population, but you don't want to reflect that difference in your analysis, then you can use equal counts stratified sampling to generate samples where each subgroup has the same amount of data. For example, if you are analyzing blood types, O is the most common blood type worldwide, but you may wish to have equal amounts of O, A, B, and AB in your sample.\n",
    "\n",
    "`attrition_pop` is available; `pandas` is loaded with its usual alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get 30 employees from each Education group\n",
    "# attrition_eq = attrition_pop.groupby('Education')\\\n",
    "# \t.sample(n=30, random_state=2022)      \n",
    "\n",
    "# # Get the proportions from attrition_eq\n",
    "# education_counts_eq = attrition_eq[\"Education\"].value_counts(normalize = True)\n",
    "\n",
    "# # Print the results\n",
    "# print(education_counts_eq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified sampling provides rules about the probability of picking rows from your dataset at the subgroup level. A generalization of this is weighted sampling, which lets you specify rules about the probability of picking rows at the row level. The probability of picking any given row is proportional to the weight value for that row.\n",
    "\n",
    "`attrition_pop` is available; `pandas`, `matplotlib.pyplot`, and numpy are loaded with their usual aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot YearsAtCompany from attrition_pop as a histogram\n",
    "# attrition_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
    "# plt.show()\n",
    "\n",
    "# # Sample 400 employees weighted by YearsAtCompany\n",
    "# attrition_weight = attrition_pop.sample(n=400, weights=\"YearsAtCompany\")\n",
    "\n",
    "# # Plot YearsAtCompany from attrition_weight as a histogram\n",
    "# attrition_weight['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is higher? The mean `YearsAtCompany` from `attrition_pop` or the mean `YearsAtCompany` from `attrition_weight`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(attrition_pop[\"YearsAtCompany\"].mean())\n",
    "# print(attrition_weight[\"YearsAtCompany\"].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sample mean."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster sampling is a two-stage sampling technique that is closely related to stratified sampling. First, you randomly sample which subgroups to include in the sample, then randomly sample rows within each subgroup.\n",
    "\n",
    "In which of the following situations would cluster sampling be preferable to stratified sampling?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collecting an overall sample requires lots of travel from one group to another to collect samples within each group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing cluster sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know when to use cluster sampling, it's time to put it into action. In this exercise, you'll explore the `JobRole` column of the attrition dataset. You can think of each job role as a subgroup of the whole population of employees.\n",
    "\n",
    "`attrition_pop` is available; `pandas` is loaded with its usual alias, and the `random` package is available. A seed of 19790801 has also been set with `random.seed()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of unique JobRole values\n",
    "# job_roles_pop = list(attrition_pop['JobRole'].unique())\n",
    "\n",
    "# # Randomly sample four JobRole values\n",
    "# job_roles_samp = random.sample(job_roles_pop, k=4)\n",
    "\n",
    "# # Filter for rows where JobRole is in job_roles_samp\n",
    "# jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)\n",
    "# attrition_filtered = attrition_pop[jobrole_condition]\n",
    "\n",
    "\n",
    "# # Remove categories with no rows\n",
    "# attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()\n",
    "\n",
    "# # Randomly sample 10 employees from each sampled job role\n",
    "# attrition_clust = attrition_filtered.groupby('JobRole').sample(n = 10, random_state = 2022)\n",
    "\n",
    "# # Print the sample\n",
    "# print(attrition_clust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 kinds of sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to compare the performance of point estimates using simple, stratified, and cluster sampling. Before doing that, you'll have to set up the samples.\n",
    "\n",
    "You'll use the `RelationshipSatisfaction` column of the `attrition_pop` dataset, which categorizes the employee's relationship with the company. It has four levels: `Low`, `Medium`, `High`, and `Very_High`. `pandas` has been loaded with its usual alias, and the `random` package has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform simple random sampling to get 0.25 of the population\n",
    "# attrition_srs = attrition_pop.sample(frac = 0.25, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform stratified sampling to get 0.25 of each relationship group\n",
    "# attrition_strat = attrition_pop.groupby(\"RelationshipSatisfaction\").sample(frac = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of unique RelationshipSatisfaction values\n",
    "# satisfaction_unique = list(attrition_pop[\"RelationshipSatisfaction\"].unique())\n",
    "\n",
    "# # Randomly sample 2 unique satisfaction values\n",
    "# satisfaction_samp = random.sample(satisfaction_unique, 2)\n",
    "\n",
    "# # Filter for satisfaction_samp and clear unused categories from RelationshipSatisfaction\n",
    "# satis_condition = attrition_pop[\"RelationshipSatisfaction\"].isin(satisfaction_samp)\n",
    "# attrition_clust_prep = attrition_pop[satis_condition]\n",
    "# attrition_clust_prep['RelationshipSatisfaction'] = attrition_clust_prep['RelationshipSatisfaction'].cat.remove_unused_categories()\n",
    "\n",
    "# # Perform cluster sampling on the selected group, getting 0.25 of attrition_pop\n",
    "# attrition_clust = attrition_clust_prep.groupby(\"RelationshipSatisfaction\").sample(n = len(attrition_pop)//4, random_state = 2022)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing point estimates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have three types of sample (simple, stratified, and cluster), you can compare point estimates from each sample to the population parameter. That is, you can calculate the same summary statistic on each sample and see how it compares to the summary statistic for the population.\n",
    "\n",
    "Here, we'll look at how satisfaction with the company affects whether or not the employee leaves the company. That is, you'll calculate the proportion of employees who left the company (they have an `Attrition` value of 1) for each value of `RelationshipSatisfaction`.\n",
    "\n",
    "`attrition_pop`, `attrition_srs`, `attrition_strat`, and `attrition_clust` are available; pandas is loaded with its usual alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mean Attrition by RelationshipSatisfaction group\n",
    "# mean_attrition_pop = attrition_pop.groupby(\"RelationshipSatisfaction\")[\"Attrition\"].mean()\n",
    "\n",
    "# # Print the result\n",
    "# print(mean_attrition_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the same thing for the simple random sample \n",
    "# mean_attrition_srs =  attrition_srs.groupby(\"RelationshipSatisfaction\")[\"Attrition\"].mean()\n",
    "\n",
    "# # Print the result\n",
    "# print(mean_attrition_srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the same thing for the stratified sample \n",
    "# mean_attrition_strat = attrition_strat.groupby(\"RelationshipSatisfaction\")[\"Attrition\"].mean()\n",
    "\n",
    "# # Print the result\n",
    "# print(mean_attrition_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the same thing for the cluster sample \n",
    "# mean_attrition_clust =  attrition_clust.groupby(\"RelationshipSatisfaction\")[\"Attrition\"].mean()\n",
    "\n",
    "# # Print the result\n",
    "# print(mean_attrition_clust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
