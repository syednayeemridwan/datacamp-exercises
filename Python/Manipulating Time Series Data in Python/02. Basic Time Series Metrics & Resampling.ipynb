{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the performance of several asset classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have seen in the video how you can easily compare several time series by normalizing their starting points to 100, and plot the result.\n",
    "\n",
    "To broaden your perspective on financial markets, let's compare four key assets: stocks, bonds, gold, and oil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import data here\n",
    "# prices = pd.read_csv('asset_classes.csv', parse_dates=['DATE'], index_col='DATE')\n",
    "\n",
    "# # Inspect prices here\n",
    "# print(prices.info())\n",
    "\n",
    "# # Select first prices\n",
    "# first_prices = prices.iloc[0]\n",
    "\n",
    "# # Create normalized\n",
    "# normalized = prices.div(first_prices).mul(100)\n",
    "\n",
    "# # Plot normalized\n",
    "# normalized.plot()\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing stock prices with a benchmark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also learned in the video how to compare the performance of various stocks against a benchmark. Now you'll learn more about the stock market by comparing the three largest stocks on the NYSE to the Dow Jones Industrial Average, which contains the 30 largest US companies.\n",
    "\n",
    "The three largest companies on the NYSE are:\n",
    "```\n",
    "Company\t            Stock Ticker\n",
    "Johnson & Johnson\t    JNJ\n",
    "Exxon Mobil\t            XOM\n",
    "JP Morgan Chase\t        JPM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import stock prices and index here\n",
    "# stocks = pd.read_csv('nyse.csv', parse_dates=['date'], index_col='date')\n",
    "# dow_jones = pd.read_csv('dow_jones.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# # Concatenate data and inspect result here\n",
    "# data = pd.concat([stocks,dow_jones],axis=1)\n",
    "# print(data.info())\n",
    "\n",
    "# # Normalize and plot your data here\n",
    "# data.div(data.iloc[0]).mul(100).plot()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance difference vs benchmark index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the video, you learned how to calculate and plot the performance difference of a stock in percentage points relative to a benchmark index.\n",
    "\n",
    "Let's compare the performance of Microsoft (MSFT) and Apple (AAPL) to the S&P 500 over the last 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create tickers\n",
    "# tickers = ['MSFT', 'AAPL']\n",
    "\n",
    "# # Import stock data here\n",
    "# stocks = pd.read_csv('msft_aapl.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# # Import index here\n",
    "# sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# # Concatenate stocks and index here\n",
    "# data = pd.concat([stocks, sp500], axis=1).dropna()\n",
    "\n",
    "# # Normalize data\n",
    "# normalized = data.div(data.iloc[0]).mul(100)\n",
    "\n",
    "# # Subtract the normalized index from the normalized stock prices, and plot the result\n",
    "# normalized[tickers].sub(normalized['SP500'], axis=0).plot()\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert monthly to weekly data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have learned in the video how to use `.reindex()` to conform an existing time series to a `DateTimeIndex` at a different frequency.\n",
    "\n",
    "Let's practice this method by creating monthly data and then converting this data to weekly frequency while applying various fill logic options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set start and end dates\n",
    "# start = '2016-1-1'\n",
    "# end = '2016-2-29'\n",
    "\n",
    "# # Create monthly_dates here\n",
    "# monthly_dates = pd.date_range(start=start, end=end, freq='M')\n",
    "\n",
    "# # Create monthly here\n",
    "# monthly = pd.Series(data=[1,2], index=monthly_dates)\n",
    "# print(monthly)\n",
    "\n",
    "# # Create weekly_dates here\n",
    "# weekly_dates = pd.date_range(start=start, end=end, freq='W')\n",
    "\n",
    "# # Print monthly, reindexed using weekly_dates\n",
    "# print(monthly.reindex(weekly_dates))\n",
    "# print(monthly.reindex(weekly_dates, method='bfill'))\n",
    "# print(monthly.reindex(weekly_dates, method='ffill'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create weekly from monthly unemployment data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The civilian US unemployment rate is reported monthly. You may need more frequent data, but that's no problem because you just learned how to upsample a time series.\n",
    "\n",
    "You'll work with the time series data for the last 20 years, and apply a few options to fill in missing values before plotting the weekly series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import data here\n",
    "# data = pd.read_csv( 'unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# # Show first five rows of weekly series\n",
    "# print(data.asfreq('W').head(5))\n",
    "\n",
    "# # Show first five rows of weekly series with bfill option\n",
    "# print(data.asfreq('W', method='bfill').head(5))\n",
    "\n",
    "# # Create weekly series with ffill option and show first five rows\n",
    "# weekly_ffill = data.asfreq('W', method='ffill')\n",
    "# print(weekly_ffill.head(5))\n",
    "\n",
    "# # Plot weekly_fill starting 2015 here \n",
    "# weekly_ffill['2015':].plot()\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use interpolation to create weekly employment data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have recently used the civilian US unemployment rate, and converted it from monthly to weekly frequency using simple `forward` or `backfill` methods.\n",
    "\n",
    "Compare your previous approach to the new `.interpolate()` method that you learned about in this video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect data here\n",
    "# print(monthly.info())\n",
    "\n",
    "# # Create weekly dates\n",
    "# weekly_dates = pd.date_range(start = monthly.index.min(), end = monthly.index.max(), freq = 'W' )\n",
    "\n",
    "# # Reindex monthly to weekly data\n",
    "# weekly = monthly.reindex(weekly_dates)\n",
    "\n",
    "# # Create ffill and interpolated columns\n",
    "# weekly['ffill'] = weekly.UNRATE.ffill()\n",
    "# weekly['interpolated'] = weekly.UNRATE.interpolate()\n",
    "\n",
    "# # Plot weekly\n",
    "# weekly.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate debt/GDP and compare to unemployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have learned how to interpolate time series, you can now apply this new skill to the quarterly debt/GDP series, and compare the result to the monthly unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import & inspect data here\n",
    "# data = pd.read_csv('debt_unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "# print(data.info())\n",
    "\n",
    "# # Interpolate and inspect here\n",
    "# interpolated = data.interpolate()\n",
    "# print(interpolated.info())\n",
    "\n",
    "# # Plot interpolated data here\n",
    "# interpolated.plot(secondary_y='Unemployment')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare weekly, monthly and annual ozone trends for NYC & LA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have seen in the video how to downsample and aggregate time series on air quality.\n",
    "\n",
    "First, you'll apply this new skill to ozone data for both NYC and LA since 2000 to compare the air quality trend at weekly, monthly and annual frequencies and explore how different resampling periods impact the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import and inspect data here\n",
    "# ozone = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date')\n",
    "# print(ozone.info())\n",
    "\n",
    "# # Calculate and plot the weekly average ozone trend\n",
    "# ozone.resample('W').mean().plot()\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate and plot the monthly average ozone trend\n",
    "# ozone.resample('M').mean().plot()\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate and plot the annual average ozone trend\n",
    "# ozone.resample('A').mean().plot()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare monthly average stock prices for Facebook and Google"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll apply your new resampling skills to daily stock price series for Facebook and Google for the 2015-2016 period to compare the trend of the monthly averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import and inspect data here\n",
    "# stocks = pd.read_csv('stocks.csv',parse_dates=['date'], index_col='date')\n",
    "# print(stocks.info())\n",
    "\n",
    "# # Calculate and plot the monthly averages\n",
    "# monthly_average = stocks.resample('M').mean()\n",
    "\n",
    "# monthly_average.plot(subplots=True)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare quarterly GDP growth rate and stock returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your new skill to downsample and aggregate time series, you can compare higher-frequency stock price series to lower-frequency economic time series.\n",
    "\n",
    "As a first example, let's compare the quarterly GDP growth rate to the quarterly rate of return on the (resampled) Dow Jones Industrial index of 30 large US stocks.\n",
    "\n",
    "GDP growth is reported at the beginning of each quarter for the previous quarter. To calculate matching stock returns, you'll resample the stock index to quarter start frequency using the alias 'QS', and aggregating using the `.first()` observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import and inspect gdp_growth here\n",
    "# gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=['date'], index_col='date')\n",
    "# print(gdp_growth.info())\n",
    "\n",
    "# # Import and inspect djia here\n",
    "# djia =  pd.read_csv('djia.csv', parse_dates=['date'], index_col='date')\n",
    "# print(djia.info())\n",
    "\n",
    "# # Calculate djia quarterly returns here \n",
    "# djia_quarterly = djia.resample('QS').first()\n",
    "# djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "\n",
    "# # Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
    "# data = pd.concat([gdp_growth , djia_quarterly_return],axis=1)\n",
    "# data.columns = [ 'gdp' , 'djia']\n",
    "# data.plot()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize monthly mean, median and standard deviation of S&P500 returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have also learned how to calculate several aggregate statistics from upsampled data.\n",
    "\n",
    "Let's use this to explore how the monthly mean, median and standard deviation of daily S&P500 returns have trended over the last 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import data here\n",
    "# sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
    "# print(type(sp500))\n",
    "# # Calculate daily returns here\n",
    "# daily_returns = sp500.squeeze().pct_change()\n",
    "# print(type(daily_returns))\n",
    "# # Resample and calculate statistics\n",
    "# stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
    "\n",
    "# # Plot stats here\n",
    "# stats.plot()\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc575bfddb5c8ca4bb6a4f4dcdd32abc104b5fa4177361381c432fff36ce3e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
