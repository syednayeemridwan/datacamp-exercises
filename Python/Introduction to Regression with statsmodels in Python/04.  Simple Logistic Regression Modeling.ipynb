{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the explanatory variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the response variable is logical, all the points lie on the y=0 and y=1 lines, making it difficult to see what is happening. In the video, until you saw the trend line, it wasn't clear how the explanatory variable was distributed on each line. This can be solved with a histogram of the explanatory variable, grouped by the response.\n",
    "\n",
    "You will use these histograms to get to know the financial services churn dataset seen in the video.\n",
    "\n",
    "`churn` is available as a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the histograms of time_since_last_purchase split by has_churned\n",
    "# sns.displot(data=churn, x = \"time_since_last_purchase\", col = \"has_churned\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Redraw the plot with time_since_first_purchase\n",
    "# sns.displot(data=churn, x = \"time_since_first_purchase\", col = \"has_churned\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing linear and logistic models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with linear regressions, `regplot()` will draw model predictions for a logistic regression without you having to worry about the modeling code yourself. To see how the predictions differ for linear and logistic regressions, try drawing both trend lines side by side. Spoiler: you should see a linear (straight line) trend from the linear model, and a logistic (S-shaped) trend from the logistic model.\n",
    "\n",
    "`churn` is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw a linear regression trend line and a scatter plot of time_since_first_purchase vs. has_churned\n",
    "# sns.regplot(x=\"time_since_first_purchase\",\n",
    "#             y=\"has_churned\",\n",
    "#             data=churn, \n",
    "#             ci=None,\n",
    "#             line_kws={\"color\": \"red\"})\n",
    "\n",
    "# # Draw a logistic regression trend line and a scatter plot of time_since_first_purchase vs. has_churned\n",
    "# sns.regplot(x=\"time_since_first_purchase\",\n",
    "#             y=\"has_churned\",\n",
    "#             data=churn, \n",
    "#             ci=None,\n",
    "#             logistic = True,\n",
    "#             line_kws={\"color\": \"blue\"})\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with logit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression requires another function from `statsmodels.formula.api`: `logit()`. It takes the same arguments as `ols()`: a `formula` and `data` argument. You then use `.fit()` to fit the model to the data.\n",
    "\n",
    "Here, you'll model how the length of relationship with a customer affects churn.\n",
    "\n",
    "`churn` is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import logit\n",
    "# from statsmodels.formula.api import logit\n",
    "\n",
    "# # Fit a logistic regression of churn vs. length of relationship using the churn dataset\n",
    "\n",
    "# mdl_churn_vs_relationship = logit(\" has_churned ~ time_since_first_purchase\", data = churn).fit()\n",
    "\n",
    "# # Print the parameters of the fitted model\n",
    "# print(mdl_churn_vs_relationship.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four main ways of expressing the prediction from a logistic regression model â€“ we'll look at each of them over the next four exercises. Firstly, since the response variable is either \"yes\" or \"no\", you can make a prediction of the probability of a \"yes\". Here, you'll calculate and visualize these probabilities.\n",
    "\n",
    "Two variables are available:\n",
    "\n",
    "- `mdl_churn_vs_relationship` is the fitted logistic regression model of `has_churned` versus time_since_first_purchase`.\n",
    "- `explanatory_data` is a DataFrame of explanatory values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create prediction_data\n",
    "# prediction_data = explanatory_data.assign(\n",
    "#   has_churned = mdl_churn_vs_relationship.predict(explanatory_data)\n",
    "# )\n",
    "\n",
    "# # Print the head\n",
    "# print(prediction_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create prediction_data\n",
    "# prediction_data = explanatory_data.assign(\n",
    "#     has_churned = mdl_churn_vs_relationship.predict(explanatory_data)\n",
    "# )\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Create a scatter plot with logistic trend line\n",
    "# sns.regplot( x = \"time_since_first_purchase\", y = \"has_churned\",\n",
    "# data = churn, logistic = True)\n",
    "\n",
    "# # Overlay with prediction_data, colored red\n",
    "# sns.scatterplot( x = \"time_since_first_purchase\", y = \"has_churned\",\n",
    "# data = prediction_data, color =\"red\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most likely outcome"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When explaining your results to a non-technical audience, you may wish to side-step talking about probabilities and simply explain the most likely outcome. That is, rather than saying there is a 60% chance of a customer churning, you say that the most likely outcome is that the customer will churn. The trade-off here is easier interpretation at the cost of nuance.\n",
    "\n",
    "`mdl_churn_vs_relationship`, `explanatory_data`, and `prediction_data` are available from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update prediction data by adding most_likely_outcome\n",
    "# prediction_data[\"most_likely_outcome\"] = np.round(prediction_data[\"has_churned\"])\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Create a scatter plot with logistic trend line (from previous exercise)\n",
    "# sns.regplot(x=\"time_since_first_purchase\",\n",
    "#             y=\"has_churned\",\n",
    "#             data=churn,\n",
    "#             ci=None,\n",
    "#             logistic=True)\n",
    "\n",
    "# # Overlay with prediction_data, colored red\n",
    "# sns.scatterplot(x=\"time_since_first_purchase\",\n",
    "#             y=\"most_likely_outcome\",\n",
    "#             data=prediction_data,\n",
    "#             color = \"red\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odds ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odds ratios compare the probability of something happening with the probability of it not happening. This is sometimes easier to reason about than probabilities, particularly when you want to make decisions about choices. For example, if a customer has a 20% chance of churning, it may be more intuitive to say \"the chance of them not churning is four times higher than the chance of them churning\".\n",
    "\n",
    "`mdl_churn_vs_relationship`, `explanatory_data`, and `prediction_data` are available from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update prediction data with odds_ratio\n",
    "# prediction_data[\"odds_ratio\"] = prediction_data[\"has_churned\"] / (1 - prediction_data[\"has_churned\"])\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Create a line plot of odds_ratio vs time_since_first_purchase\n",
    "# sns.lineplot(x = \"time_since_first_purchase\", y= \"odds_ratio\", data = prediction_data)\n",
    "\n",
    "# # Add a dotted horizontal line at odds_ratio = 1\n",
    "# plt.axhline(y=1, linestyle=\"dotted\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log odds ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One downside to probabilities and odds ratios for logistic regression predictions is that the prediction lines for each are curved. This makes it harder to reason about what happens to the prediction when you make a change to the explanatory variable. The logarithm of the odds ratio (the \"log odds ratio\" or \"logit\") does have a linear relationship between predicted response and explanatory variable. That means that as the explanatory variable changes, you don't see dramatic changes in the response metric - only linear changes.\n",
    "\n",
    "Since the actual values of log odds ratio are less intuitive than (linear) odds ratio, for visualization purposes it's usually better to plot the odds ratio and apply a log transformation to the y-axis scale.\n",
    "\n",
    "`mdl_churn_vs_relationship`, `explanatory_data`, and `prediction_data` are available from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update prediction data with log_odds_ratio\n",
    "# prediction_data[\"log_odds_ratio\"] = np.log(prediction_data[\"odds_ratio\"])\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Update the line plot: log_odds_ratio vs. time_since_first_purchase\n",
    "# sns.lineplot(x=\"time_since_first_purchase\",\n",
    "#              y=\"log_odds_ratio\",\n",
    "#              data=prediction_data)\n",
    "\n",
    "# # Add a dotted horizontal line at log_odds_ratio = 0\n",
    "# plt.axhline(y=0, linestyle=\"dotted\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the confusion matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix (occasionally called a confusion table) is the basis of all performance metrics for models with a categorical response (such as a logistic regression). It contains the counts of each actual response-predicted response pair. In this case, where there are two possible responses (churn or not churn), there are four overall outcomes.\n",
    "\n",
    "- True positive: The customer churned and the model predicted they would.\n",
    "- False positive: The customer didn't churn, but the model predicted they would.\n",
    "- True negative: The customer didn't churn and the model predicted they wouldn't.\n",
    "- False negative: The customer churned, but the model predicted they wouldn't.\n",
    "\n",
    "`churn` and `mdl_churn_vs_relationship` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the actual responses\n",
    "# actual_response = churn[\"has_churned\"]\n",
    "\n",
    "# # Get the predicted responses\n",
    "# predicted_response = np.round(mdl_churn_vs_relationship.predict())\n",
    "\n",
    "# # Create outcomes as a DataFrame of both Series\n",
    "# outcomes = pd.DataFrame({\"actual_response\":actual_response,\n",
    "#                          \"predicted_response\":predicted_response})\n",
    "\n",
    "# # Print the outcomes\n",
    "# print(outcomes.value_counts(sort = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing a mosaic plot of the confusion matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While calculating the performance matrix might be fun, it would become tedious if you needed multiple confusion matrices of different models. Luckily, the `.pred_table()` method can calculate the confusion matrix for you.\n",
    "\n",
    "Additionally, you can use the output from the `.pred_table()` method to visualize the confusion matrix, using the `mosaic()` function.\n",
    "\n",
    "`churn` and `mdl_churn_vs_relationship` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import mosaic from statsmodels.graphics.mosaicplot\n",
    "# from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "# # Calculate the confusion matrix conf_matrix\n",
    "# conf_matrix = mdl_churn_vs_relationship.pred_table()\n",
    "\n",
    "# # Print it\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # Draw a mosaic plot of conf_matrix\n",
    "# mosaic(conf_matrix)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, sensitivity, specificity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of performance metrics can be computed from a confusion matrix. For logistic regression, three of them in particular are important: accuracy, sensitivity, and specificity. Can you identify what each of those terms mean in the context of the churn model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/04.13.jpg\"  style=\"width: 400px, height: 300px;\"/></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring logistic model performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several metrics exist for measuring the performance of a logistic regression model. In this last exercise, you'll manually calculate accuracy, sensitivity, and specificity. Recall the following definitions:\n",
    "\n",
    "- Accuracy is the proportion of predictions that are correct.\n",
    "- Sensitivity is the proportion of true observations that are correctly predicted by the model as being true.\n",
    "- Specificity is the proportion of false observations that are correctly predicted by the model as being false.\n",
    "\n",
    "`churn`, `mdl_churn_vs_relationship`, and `conf_matrix` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract TN, TP, FN and FP from conf_matrix\n",
    "# TN = conf_matrix[0,0]\n",
    "# TP = conf_matrix[1,1]\n",
    "# FN = conf_matrix[1,0]\n",
    "# FP = conf_matrix[0,1]\n",
    "\n",
    "# # Calculate and print the accuracy\n",
    "# accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# print(\"accuracy: \", accuracy)\n",
    "\n",
    "# # Calculate and print the sensitivity\n",
    "# sensitivity = TP / (TP + FN)\n",
    "# print(\"sensitivity: \", sensitivity)\n",
    "\n",
    "# # Calculate and print the specificity\n",
    "# specificity = TN / (TN + FP)\n",
    "# print(\"specificity: \", specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
