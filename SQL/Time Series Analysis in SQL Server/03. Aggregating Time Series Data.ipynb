{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize data over a time frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several useful aggregate functions in SQL Server which we can use to summarize our data over time frames and gain insights. In the following example, you will look at a set of incident reports at a fictional company. They have already rolled up their incidents to the daily grain, giving us a number of incidents per type and day. We would like to investigate further and review incidents over a three-month period, from August 1 through October 31st, and gain basic insights through aggregation.\n",
    "\n",
    "The key aggregate functions we will use are `COUNT()`, `SUM()`, `MIN()`, and `MAX()`. In the next exercise, we will look at some of the statistical aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Fill in the appropriate aggregate functions\n",
    "SELECT\n",
    "\tit.IncidentType,\n",
    "\tCOUNT(1) AS NumberOfRows,\n",
    "\tSUM(ir.NumberOfIncidents) AS TotalNumberOfIncidents,\n",
    "\tMIN(ir.NumberOfIncidents) AS MinNumberOfIncidents,\n",
    "\tMAX(ir.NumberOfIncidents) AS MaxNumberOfIncidents,\n",
    "\tMIN(ir.IncidentDate) As MinIncidentDate,\n",
    "\tMAX(ir.IncidentDate) AS MaxIncidentDate\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.IncidentType it\n",
    "\t\tON ir.IncidentTypeID = it.IncidentTypeID\n",
    "WHERE\n",
    "\tir.IncidentDate BETWEEN '2019-08-01' AND '2019-10-31'\n",
    "GROUP BY\n",
    "\tit.IncidentType;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating distinct counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `COUNT()` function has a variant which can be quite useful: `COUNT(DISTINCT)`. This distinct count function allows us to calculate the number of unique elements in a data set, so `COUNT(DISTINCT x.Y)` will get the unique number of values for column `Y` on the table aliased as `x`.\n",
    "\n",
    "In this example, we will continue to look at incident rollup data in the `dbo.IncidentRollup` table. Management would like to know how many unique incident types we have in our three-month data set as well as the number of days with incidents. They already know the total number of incidents because you gave them that information in the last exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Fill in the functions and columns\n",
    "SELECT\n",
    "\tCOUNT(DISTINCT ir.IncidentTypeID) AS NumberOfIncidentTypes,\n",
    "\tCOUNT(DISTINCT ir.IncidentDate) AS NumberOfDaysWithIncidents\n",
    "FROM dbo.IncidentRollup ir\n",
    "WHERE\n",
    "ir.IncidentDate BETWEEN '2019-08-01' AND '2019-10-31';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating filtered aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to count the number of occurrences of an event given some filter criteria, we can take advantage of aggregate functions like `SUM()`,` MIN()`, and `MAX()`, as well as `CASE` expressions. For example, `SUM(CASE WHEN ir.IncidentTypeID = 1 THEN 1 ELSE 0 END)` will return the count of incidents associated with incident type 1. If you include one `SUM()` statement for each incident type, you have pivoted the data set by incident type ID.\n",
    "\n",
    "In this scenario, management would like us to tell them, by incident type, how many \"big-incident\" days we have had versus \"small-incident\" days. Management defines a big-incident day as having more than 5 occurrences of the same incident type on the same day, and a small-incident day has between 1 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\tit.IncidentType,\n",
    "    -- Fill in the appropriate expression\n",
    "\tSUM(CASE WHEN ir.NumberOfIncidents > 5 THEN 1 ELSE 0 END) AS NumberOfBigIncidentDays,\n",
    "    -- Number of incidents will always be at least 1, so\n",
    "    -- no need to check the minimum value, just that it's\n",
    "    -- less than or equal to 5\n",
    "    SUM(CASE WHEN ir.NumberOfIncidents <= 5 THEN 1 ELSE 0 END) AS NumberOfSmallIncidentDays\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.IncidentType it\n",
    "\t\tON ir.IncidentTypeID = it.IncidentTypeID\n",
    "WHERE\n",
    "\tir.IncidentDate BETWEEN '2019-08-01' AND '2019-10-31'\n",
    "GROUP BY\n",
    "it.IncidentType;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with statistical aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Server offers several aggregate functions for statistical purpose. The `AVG()` function generates the mean of a sample. `STDEV()` and `STDEVP()` give us the standard deviation of a sample and of a population, respectively. `VAR()` and `VARP()` give us the variance of a sample and a population, respectively. These are in addition to the aggregate functions we learned about in the previous exercise, including `SUM()`, `COUNT()`, `MIN()`, and `MAX()`.\n",
    "\n",
    "In this exercise, we will look once more at incident rollup and incident type data, this time for quarter 2 of calendar year 2020. We would like to get an idea of how much spread there is in incident occurrence--that is, if we see a consistent number of incidents on a daily basis or if we see wider swings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Fill in the missing function names\n",
    "SELECT\n",
    "\tit.IncidentType,\n",
    "\tAVG(ir.NumberOfIncidents) AS MeanNumberOfIncidents,\n",
    "\tAVG(CAST(ir.NumberOfIncidents AS DECIMAL(4,2))) AS MeanNumberOfIncidents,\n",
    "\tSTDEV(ir.NumberOfIncidents) AS NumberOfIncidentsStandardDeviation,\n",
    "\tVAR(ir.NumberOfIncidents) AS NumberOfIncidentsVariance,\n",
    "\tCOUNT(1) AS NumberOfRows\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.IncidentType it\n",
    "\t\tON ir.IncidentTypeID = it.IncidentTypeID\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "WHERE\n",
    "\tc.CalendarQuarter = 2\n",
    "\tAND c.CalendarYear = 2020\n",
    "GROUP BY\n",
    "it.IncidentType;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating median in SQL Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no `MEDIAN()` function in SQL Server. The closest we have is `PERCENTILE_CONT()`, which finds the value at the nth percentile across a data set.\n",
    "\n",
    "We would like to figure out how far the median differs from the mean by incident type in our incident rollup set. To do so, we can compare the `AVG()` function from the prior exercise to `PERCENTILE_CONT()`. These are window functions, which we will cover in more detail in chapter 4. For now, know that `PERCENTILE_CONT()` takes a parameter, the percentile (a decimal ranging from from 0. to 1.). The percentile must be within an ordered group inside the `WITHIN GROUP` clause and `OVER` a certain range if you need to partition the data. In the `WITHIN GROUP` section, we need to order by the column whose 50th percentile we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT DISTINCT\n",
    "\tit.IncidentType,\n",
    "\tAVG(CAST(ir.NumberOfIncidents AS DECIMAL(4,2)))\n",
    "\t    OVER(PARTITION BY it.IncidentType) AS MeanNumberOfIncidents,\n",
    "    --- Fill in the missing value\n",
    "\tPERCENTILE_CONT(0.5)\n",
    "    \t-- Inside our group, order by number of incidents DESC\n",
    "    \tWITHIN GROUP (ORDER BY ir.NumberOfIncidents DESC)\n",
    "        -- Do this for each IncidentType value\n",
    "        OVER (PARTITION BY it.IncidentTypeID) AS MedianNumberOfIncidents,\n",
    "\tCOUNT(1) OVER (PARTITION BY it.IncidentType) AS NumberOfRows\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.IncidentType it\n",
    "\t\tON ir.IncidentTypeID = it.IncidentTypeID\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "WHERE\n",
    "\tc.CalendarQuarter = 2\n",
    "\tAND c.CalendarYear = 2020;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample to a daily grain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling up data to a higher grain is a common analytical task. We may have a set of data with specific time stamps and a need to observe aggregated results. In SQL Server, there are several techniques available depending upon your desired grain.\n",
    "\n",
    "For these exercises, we will look at a fictional day spa. Spa management sent out coupons to potential new customers for the period June 16th through 20th of 2020 and would like to see if this campaign spurred on new visits.\n",
    "\n",
    "In this exercise, we will look at one of the simplest downsampling techniques: converting a `DATETIME2` or `DATETIME` data type to a data type with just a date and no time component: the `DATE` type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\t-- Downsample to a daily grain\n",
    "    -- Cast CustomerVisitStart as a date\n",
    "\tCAST(dsv.CustomerVisitStart AS DATE) AS Day,\n",
    "\tSUM(dsv.AmenityUseInMinutes) AS AmenityUseInMinutes,\n",
    "\tCOUNT(1) AS NumberOfAttendees\n",
    "FROM dbo.DaySpaVisit dsv\n",
    "WHERE\n",
    "\tdsv.CustomerVisitStart >= '2020-06-11'\n",
    "\tAND dsv.CustomerVisitStart < '2020-06-23'\n",
    "GROUP BY\n",
    "\t-- When we use aggregation functions like SUM or COUNT,\n",
    "    -- we need to GROUP BY the non-aggregated columns\n",
    "\tCAST(dsv.CustomerVisitStart AS DATE)\n",
    "ORDER BY\n",
    "\tDay;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample to a weekly grain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management would like to see how well people have utilized the spa in 2020. They would like to see results by week, reviewing the total number of minutes of amenity usage, the number of attendees, and the customer with the largest customer ID that week to see if new customers are coming in.\n",
    "\n",
    "We can use functions in SQL Server to downsample to a fixed grain like this. One such function is `DATEPART()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\t-- Downsample to a weekly grain\n",
    "\tDATEPART(WEEK, dsv.CustomerVisitStart) AS Week,\n",
    "\tSUM(dsv.AmenityUseInMinutes) AS AmenityUseInMinutes,\n",
    "\t-- Find the customer with the largest customer ID for that week\n",
    "\tMAX(dsv.CustomerID) AS HighestCustomerID,\n",
    "\tCOUNT(1) AS NumberOfAttendees\n",
    "FROM dbo.DaySpaVisit dsv\n",
    "WHERE\n",
    "\tdsv.CustomerVisitStart >= '2020-01-01'\n",
    "\tAND dsv.CustomerVisitStart < '2021-01-01'\n",
    "GROUP BY\n",
    "\t-- When we use aggregation functions like SUM or COUNT,\n",
    "    -- we need to GROUP BY the non-aggregated columns\n",
    "\tDATEPART(WEEK, dsv.CustomerVisitStart)\n",
    "ORDER BY\n",
    "\tWeek;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample using a calendar table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management liked the weekly report but they wanted to see every week in 2020, not just the weeks with amenity usage. We can use a calendar table to solve this problem: the calendar table includes all of the weeks, so we can join it to the `dbo.DaySpaVisit` table to find our answers.\n",
    "\n",
    "Management would also like to see the first day of each calendar week, as that provides important context to report viewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\t-- Determine the week of the calendar year\n",
    "\tc.CalendarWeekOfYear,\n",
    "\t-- Determine the earliest DATE in this group\n",
    "    -- This is NOT the DayOfWeek column\n",
    "\tMIN(c.FirstDayOfWeek) AS FirstDateOfWeek,\n",
    "\tISNULL(SUM(dsv.AmenityUseInMinutes), 0) AS AmenityUseInMinutes,\n",
    "\tISNULL(MAX(dsv.CustomerID), 0) AS HighestCustomerID,\n",
    "\tCOUNT(dsv.CustomerID) AS NumberOfAttendees\n",
    " \t\n",
    "FROM dbo.Calendar c\n",
    "\tLEFT OUTER JOIN dbo.DaySpaVisit dsv\n",
    "\t\t-- Connect dbo.Calendar with dbo.DaySpaVisit\n",
    "\t\t-- To join on CustomerVisitStart, we need to turn \n",
    "        -- it into a DATE type\n",
    "\t\tON c.Date = CAST(dsv.CustomerVisitStart AS DATE)\n",
    "WHERE\n",
    "\tc.CalendarYear = 2020\n",
    "GROUP BY\n",
    "\t-- When we use aggregation functions like SUM or COUNT,\n",
    "    -- we need to GROUP BY the non-aggregated columns\n",
    "\tc.CalendarWeekOfYear\n",
    "ORDER BY\n",
    "\tc.CalendarWeekOfYear;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a summary with ROLLUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ROLLUP` operator works best when your non-measure attributes are hierarchical. Otherwise, you may end up weird aggregation levels which don't make intuitive sense.\n",
    "\n",
    "In this scenario, we wish to aggregate the total number of security incidents in the `IncidentRollup` table. Management would like to see data aggregated by the combination of calendar year, calendar quarter, and calendar month. In addition, they would also like to see separate aggregate lines for calendar year plus calendar quarter, as well as separate aggregate lines for each calendar year. Finally, they would like one more line for the grand total. We can do all of this in one operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.CalendarMonth,\n",
    "    -- Include the sum of incidents by day over each range\n",
    "\tSUM(ir.NumberOfIncidents) AS NumberOfIncidents\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "WHERE\n",
    "\tir.IncidentTypeID = 2\n",
    "GROUP BY\n",
    "\t-- GROUP BY needs to include all non-aggregated columns\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.CalendarMonth\n",
    "-- Fill in your grouping operator\n",
    "WITH ROLLUP\n",
    "ORDER BY\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.CalendarMonth;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View all aggregations with CUBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CUBE` operator provides a cross aggregation of all combinations and can be a huge number of rows. This operator works best with non-hierarchical data where you are interested in independent aggregations as well as the combined aggregations.\n",
    "\n",
    "In this scenario, we wish to find the total number of security incidents in the `IncidentRollup` table but will not follow a proper hierarchy. Instead, we will focus on aggregating several unrelated attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\t-- Use the ORDER BY clause as a guide for these columns\n",
    "    -- Don't forget that comma after the third column if you\n",
    "    -- copy from the ORDER BY clause!\n",
    "\tir.IncidentTypeID,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.WeekOfMonth,\n",
    "\tSUM(ir.NumberOfIncidents) AS NumberOfIncidents\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "WHERE\n",
    "\tir.IncidentTypeID IN (3, 4)\n",
    "GROUP BY\n",
    "\t-- GROUP BY should include all non-aggregated columns\n",
    "\tir.IncidentTypeID,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.WeekOfMonth\n",
    "-- Fill in your grouping operator\n",
    "WITH CUBE\n",
    "ORDER BY\n",
    "\tir.IncidentTypeID,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.WeekOfMonth;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate custom groupings with GROUPING SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GROUPING SETS` operator allows us to define the specific aggregation levels we desire.\n",
    "\n",
    "In this scenario, management would like to see something similar to a `ROLLUP` but without quite as much information. Instead of showing every level of aggregation in the hierarchy, management would like to see three levels: grand totals; by year; and by year, quarter, and month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.CalendarMonth,\n",
    "\tSUM(ir.NumberOfIncidents) AS NumberOfIncidents\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "WHERE\n",
    "\tir.IncidentTypeID = 2\n",
    "-- Fill in your grouping operator here\n",
    "GROUP BY GROUPING SETS\n",
    "(\n",
    "  \t-- Group in hierarchical order:  calendar year,\n",
    "    -- calendar quarter name, calendar month\n",
    "\t(c.CalendarYear, c.CalendarQuarterName, c.CalendarMonth),\n",
    "  \t-- Group by calendar year\n",
    "\t(c.CalendarYear),\n",
    "    -- This remains blank; it gives us the grand total\n",
    "\t()\n",
    ")\n",
    "ORDER BY\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarQuarterName,\n",
    "\tc.CalendarMonth;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine multiple aggregations in one query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last three exercises, we walked through the `ROLLUP`, `CUBE`, and `GROUPING SETS` grouping operators. Of these three, `GROUPING SETS` is the most customizable, allowing you to build out exactly the levels of aggregation you want. `GROUPING SETS` makes no assumptions about hierarchy (unlike `ROLLUP`) and can remain manageable with a good number of columns (unlike `CUBE`).\n",
    "\n",
    "In this exercise, we want to test several conjectures with our data:\n",
    "\n",
    "- We have seen fewer incidents per month since introducing training in November of 2019.\n",
    "- More incidents occur on Tuesday than on other weekdays.\n",
    "- More incidents occur on weekends than weekdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarMonth,\n",
    "\tc.DayOfWeek,\n",
    "\tc.IsWeekend,\n",
    "\tSUM(ir.NumberOfIncidents) AS NumberOfIncidents\n",
    "FROM dbo.IncidentRollup ir\n",
    "\tINNER JOIN dbo.Calendar c\n",
    "\t\tON ir.IncidentDate = c.Date\n",
    "GROUP BY GROUPING SETS\n",
    "(\n",
    "    -- Each non-aggregated column from above should appear once\n",
    "  \t-- Calendar year and month\n",
    "\t(c.CalendarYear, c.CalendarMonth),\n",
    "  \t-- Day of week\n",
    "\t(c.DayOfWeek),\n",
    "  \t-- Is weekend or not\n",
    "\t(c.IsWeekend),\n",
    "    -- This remains empty; it gives us the grand total\n",
    "\t()\n",
    ")\n",
    "ORDER BY\n",
    "\tc.CalendarYear,\n",
    "\tc.CalendarMonth,\n",
    "\tc.DayOfWeek,\n",
    "\tc.IsWeekend;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
