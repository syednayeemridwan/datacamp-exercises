{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A review of the LIKE operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LIKE` operator allows us to filter our queries by matching one or more characters in text data. By using the `%` wildcard we can match one or more characters in a string. This is useful when you want to return a result set that matches certain characteristics and can also be very helpful during exploratory data analysis or data cleansing tasks.\n",
    "\n",
    "Let's explore how different usage of the `%` wildcard will return different results by looking at the `film` table of the Sakila DVD Rental database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select all columns\n",
    "SELECT *\n",
    "FROM film\n",
    "-- Select only records that begin with the word 'GOLD'\n",
    "WHERE title LIKE 'GOLD%';\n",
    "\n",
    "SELECT *\n",
    "FROM film\n",
    "-- Select only records that end with the word 'GOLD'\n",
    "WHERE title LIKE '%GOLD';\n",
    "\n",
    "SELECT *\n",
    "FROM film\n",
    "-- Select only records that contain the word 'GOLD'\n",
    "WHERE title LIKE '%GOLD%';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a tsvector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You saw how to convert strings to `tsvector` and `tsquery` in the video and, in this exercise, we are going to dive deeper into what these functions actually return after converting a string to a `tsvector`. In this example, you will convert a text column from the `film` table to a `tsvector` and inspect the results. Understanding how full-text search works is the first step in more advanced machine learning and data science concepts like natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the film description as a tsvector\n",
    "SELECT to_tsvector(description)\n",
    "FROM film;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic full-text search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching text will become something you do repeatedly when building applications or exploring data sets for data science. Full-text search is helpful when performing exploratory data analysis for a natural language processing model or building a search feature into your application.\n",
    "\n",
    "In this exercise, you will practice searching a text column and match it against a string. The search will return the same result as a query that uses the `LIKE` operator with the `%` wildcard at the beginning and end of the string, but will perform much better and provide you with a foundation for more advanced full-text search queries. Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the title and description\n",
    "SELECT title, description\n",
    "FROM film\n",
    "-- Convert the title to a tsvector and match it against the tsquery \n",
    "WHERE to_tsvector(title) @@ to_tsquery('elf');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ENUM` or enumerated data types are great options to use in your database when you have a column where you want to store a fixed list of values that rarely change. Examples of when it would be appropriate to use an `ENUM` include days of the week and states or provinces in a country.\n",
    "\n",
    "Another example can be the directions on a compass (i.e., north, south, east and west.) In this exercise, you are going to create a new `ENUM` data type called `compass_position`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Create an enumerated data type, compass_position\n",
    "CREATE TYPE compass_position AS ENUM (\n",
    "  \t-- Use the four cardinal directions\n",
    "  \t'North', \n",
    "  \t'South',\n",
    "  \t'East', \n",
    "  \t'West'\n",
    ");\n",
    "-- Confirm the new data type is in the pg_type system table\n",
    "SELECT typcategory\n",
    "FROM pg_type\n",
    "WHERE typname='compass_position';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting info about user-defined data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sakila database has a user-defined `enum` data type called `mpaa_rating`. The `rating` column in the `film` table is an `mpaa_rating` type and contains the familiar rating for that film like PG or R. This is a great example of when an enumerated data type comes in handy. Film ratings have a limited number of standard values that rarely change.\n",
    "\n",
    "When you want to learn about a column or data type in your database the best place to start is the `INFORMATION_SCHEMA`. You can find information about the rating column that can help you learn about the type of data you can expect to find. For enum data types, you can also find the specific values that are valid for a particular enum by looking in the `pg_enum` system table. Let's dive into the exercises and learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the column name, data type and udt name columns\n",
    "SELECT column_name, data_type, udt_name\n",
    "FROM INFORMATION_SCHEMA.COLUMNS \n",
    "-- Filter by the rating column in the film table\n",
    "WHERE table_name='film'  AND  column_name ='rating';\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT *\n",
    "FROM pg_type \n",
    "WHERE typname='mpaa_rating'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined functions in Sakila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were running a real-life DVD Rental store, there are many questions that you may need to answer repeatedly like whether a film is in stock at a particular store or the outstanding balance for a particular customer. These types of scenarios are where user-defined functions will come in very handy. The Sakila database has several user-defined functions pre-defined. These functions are available out-of-the-box and can be used in your queries like many of the built-in functions we've learned about in this course.\n",
    "\n",
    "In this exercise, you will build a query step-by-step that can be used to produce a report to determine which film title is currently held by which customer using the `inventory_held_by_customer()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the film title and inventory ids\n",
    "SELECT \n",
    "\tf.title, \n",
    "    i.inventory_id,\n",
    "    -- Determine whether the inventory is held by a customer\n",
    "    inventory_held_by_customer(i.inventory_id) as held_by_cust\n",
    "FROM film as f \n",
    "\tINNER JOIN inventory AS i ON f.film_id=i.film_id \n",
    "WHERE\n",
    "\t-- Only include results where the held_by_cust is not null\n",
    "    inventory_held_by_customer(i.inventory_id) IS NOT NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enabling extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can use the capabilities of an extension it must be enabled. As you have previously learned, most PostgreSQL distributions come pre-bundled with many useful extensions to help extend the native features of your database. You will be working with `fuzzystrmatch` and `pg_trgm` in upcoming exercises but before you can practice using the capabilities of these extensions you will need to first make sure they are enabled in our database. In this exercise you will enable the pg_trgm extension and confirm that the fuzzystrmatch extension, which was enabled in the video, is still enabled by querying the `pg_extension` system table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Enable the pg_trgm extension\n",
    "CREATE EXTENSION IF NOT EXISTS pg_trgm;\n",
    "\n",
    "-- Select all rows extensions\n",
    "SELECT * \n",
    "FROM pg_extension;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring similarity between two strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have enabled the `fuzzystrmatch` and `pg_trgm` extensions you can begin to explore their capabilities. First, we will measure the `similarity` between the title and description from the `film` table of the Sakila database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the title and description columns\n",
    "SELECT \n",
    "  title, \n",
    "  description, \n",
    "  -- Calculate the similarity\n",
    "  similarity(title, description)\n",
    "FROM \n",
    "  film\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a closer look at how we can use the levenshtein function to match strings against text data. If you recall, the levenshtein distance represents the number of edits required to convert one string to another string being compared.\n",
    "\n",
    "In a search application or when performing data analysis on any data that contains manual user input, you will always want to account for typos or incorrect spellings. The levenshtein function provides a great method for performing this task. In this exercise, we will perform a query against the `film` table using a search string with a misspelling and use the results from `levenshtein` to determine a match. Let's check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- Select the title and description columns\n",
    "SELECT  \n",
    "  title, \n",
    "  description, \n",
    "  -- Calculate the levenshtein distance\n",
    "  levenshtein(title, 'JET NEIGHBOR') AS distance\n",
    "FROM \n",
    "  film\n",
    "ORDER BY 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we are going to use many of the techniques and concepts we learned throughout the course to generate a data set that we could use to predict whether the words and phrases used to describe a film have an impact on the number of rentals.\n",
    "\n",
    "First, you need to create a `tsvector` from the `description` column in the `film` table. You will match against a `tsquery` to determine if the phrase \"Astounding Drama\" leads to more rentals per month. Next, create a new column using the `similarity` function to rank the film descriptions based on this phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT \n",
    "  title, \n",
    "  description, \n",
    "  -- Calculate the similarity\n",
    "  similarity(description, 'Astounding Drama')\n",
    "FROM \n",
    "  film \n",
    "WHERE \n",
    "  to_tsvector(description) @@ \n",
    "  to_tsquery('Astounding & Drama') \n",
    "ORDER BY \n",
    "\tsimilarity(description, 'Astounding Drama') DESC;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
