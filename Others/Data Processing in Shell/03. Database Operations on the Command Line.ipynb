{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sql2csv documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you're trying to run a query with `sql2csv` but you've been having issues because the error message is not detailed enough to help debug the error. Which optional argument in `sql2csv` will print detailed tracebacks and logs when errors occur while using `sql2csv`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `-v` or `--verbose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand sql2csv connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a SQL database you would like to connect to using `sql2csv`, but you're not sure yet if this particular database can be connected to. sql2csv's manual does not readily have the list of possible database connectors, but `csvsql` does!\n",
    "\n",
    "Could you use `csvsql`'s manual to check what SQL database connections are currently NOT supported for `sql2csv` and for the rest of the `csvkit` suite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MongoDB (Because it is NoSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice pulling data from database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the powers of `csvkit`, we don't need to download and set up fancy database management software like MS SQL Server, DB2, PgAdmin, or TablePlus to be able to access the data inside a SQL database. We can pull data directly from our command line using `csvkit`'s `sql2csv` command.\n",
    "\n",
    "In this practice, let's walk through pulling data step by step, by applying SQL manipulations to the table `Spotify_Popularity` which dwells inside a SQLite database called `SpotifyDatabase` and then saving the output of the SQL query to a local `.csv` file `Spotify_Popularity_5Rows.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Verify database name \n",
    "ls\n",
    "\n",
    "# Pull the entire Spotify_Popularity table and print in log\n",
    "sql2csv --db \"sqlite:///SpotifyDatabase.db\" \\\n",
    "        --query \"SELECT * FROM Spotify_Popularity\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Verify database name \n",
    "ls\n",
    "\n",
    "# Query first 5 rows of Spotify_Popularity and print in log\n",
    "sql2csv --db \"sqlite:///SpotifyDatabase.db\" \\\n",
    "        --query \"SELECT * FROM Spotify_Popularity\" \\\n",
    "        | csvlook         \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Verify database name \n",
    "ls\n",
    "\n",
    "# Save query to new file Spotify_Popularity_5Rows.csv\n",
    "sql2csv --db \"sqlite:///SpotifyDatabase.db\" \\\n",
    "        --query \"SELECT * FROM Spotify_Popularity LIMIT 5\" \\\n",
    "        > Spotify_Popularity_5Rows.csv\n",
    "\n",
    "# Verify newly created file\n",
    "ls\n",
    "\n",
    "# Print preview of newly created file\n",
    "csvlook Spotify_Popularity_5Rows.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SQL to a local CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the data manipulation we want to do is just easier to do with SQL. In this situation, we want to find the shortest duration song in Spotify_MusicAttributes.csv by applying the SQL below directly to the data file.\n",
    "\n",
    "`SELECT * FROM Spotify_MusicAttributes ORDER BY duration_ms LIMIT 1`\n",
    "\n",
    "Let's go through this step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Preview CSV file\n",
    "ls\n",
    "\n",
    "# Apply SQL query to Spotify_MusicAttributes.csv\n",
    "csvsql --query \"SELECT * FROM Spotify_MusicAttributes ORDER BY duration_ms LIMIT 1\" Spotify_MusicAttributes.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Reformat the output using csvlook \n",
    "csvsql --query \"SELECT * FROM Spotify_MusicAttributes ORDER BY duration_ms LIMIT 1\" \\\n",
    "\tSpotify_MusicAttributes.csv | csvlook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Re-direct output to new file: ShortestSong.csv\n",
    "csvsql --query \"SELECT * FROM Spotify_MusicAttributes ORDER BY duration_ms LIMIT 1\" \\\n",
    "\tSpotify_MusicAttributes.csv > ShortestSong.csv\n",
    "    \n",
    "# Preview newly created file \n",
    "csvlook ShortestSong.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaner scripting via shell variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because SQL queries, by nature, can be long and complex, we will frequently need to deal with line breaks while passing in SQL queries to csvkit commands.\n",
    "\n",
    "One way to work around this is to store the SQL queries as a shell variable, then pass in the shell variable in place of the SQL query where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Preview CSV file\n",
    "ls\n",
    "\n",
    "# Store SQL query as shell variable\n",
    "sqlquery=\"SELECT * FROM Spotify_MusicAttributes ORDER BY duration_ms LIMIT 1\"\n",
    "\n",
    "# Apply SQL query to Spotify_MusicAttributes.csv\n",
    "csvsql --query \"$sqlquery\" Spotify_MusicAttributes.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining local CSV files using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csvsql` can be used to join CSV files together even when neither of them are in a database. Here, we have two CSV files `Spotify_MusicAttributes.csv` and `Spotify_Popularity.csv` that are both on song level but contain different attributes for each song. We can combine the two files together using a SQL-like JOIN, and we can do so, through the power of `csvsql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `csvcut -n Spotify_MusicAttributes.csv; csvcut -n Spotify_Popularity.csv;`\n",
    "- track_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Store SQL query as shell variable\n",
    "sql_query=\"SELECT ma.*, p.popularity FROM Spotify_MusicAttributes ma INNER JOIN Spotify_Popularity p ON ma.track_id = p.track_id\"\n",
    "\n",
    "# Join 2 local csvs into a new csv using the saved SQL\n",
    "csvsql --query \"$sql_query\" Spotify_MusicAttributes.csv Spotify_Popularity.csv > Spotify_FullData.csv\n",
    "\n",
    "# Preview newly created file\n",
    "csvstat Spotify_FullData.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice pushing data back to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to go the other way around and push local CSV files back to the database. As long as we specify the database as well as the CSV file to be loaded, `csvsql` does the rest of the work for us (e.g. inferring table schema), behind the scenes.\n",
    "\n",
    "In the following exercise, complete the command to upload `Spotify_MusicAttributes.csv` as its own table in the SQLite database `SpotifyDatabase`. Then, as a sanity check, re-pull the data from the newly created table in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Preview file\n",
    "ls\n",
    "\n",
    "# Upload Spotify_MusicAttributes.csv to database\n",
    "csvsql --db \"sqlite:///SpotifyDatabase.db\" --insert Spotify_MusicAttributes.csv\n",
    "\n",
    "# Store SQL query as shell variable\n",
    "sqlquery=\"SELECT * FROM Spotify_MusicAttributes\"\n",
    "\n",
    "# Apply SQL query to re-pull new table in database\n",
    "sql2csv --db \"sqlite:///SpotifyDatabase.db\" --query \"$sqlquery\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database and SQL with csvkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of `csvsql` and `sql2csv` allows us to go through an entire data workflow inside the terminal without needing to install and set up additional SQL clients and software. In this capstone, we will put together and pull data from a SQLite database, merge this data with a locally saved file, and finally, push a final merged file back to the database, all without ever leaving the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Store SQL for querying from SQLite database \n",
    "sqlquery_pull=\"SELECT * FROM SpotifyMostRecentData\"\n",
    "\n",
    "# Apply SQL to save table as local file \n",
    "sql2csv --db \"sqlite:///SpotifyDatabase.db\" --query \"$sqlquery_pull\" > SpotifyMostRecentData.csv\n",
    "\n",
    "# Store SQL for UNION of the two local CSV files\n",
    "sqlquery_union=\"SELECT * FROM SpotifyMostRecentData UNION ALL SELECT * FROM Spotify201812\"\n",
    "\n",
    "# Apply SQL to union the two local CSV files and save as local file\n",
    "csvsql \t--query \"$sqlquery_union\" SpotifyMostRecentData.csv Spotify201812.csv > UnionedSpotifyData.csv\n",
    "\n",
    "# Push UnionedSpotifyData.csv to database as a new table\n",
    "csvsql --db \"sqlite:///SpotifyDatabase.db\" --insert UnionedSpotifyData.csv\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('env_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e949e87132dd83f1a7623eb88007e3532b03b66b77111be347aa4a383049722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
